{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3e3e12-4376-45a5-bfcf-0ce64de8456f",
   "metadata": {},
   "source": [
    "# Assignment 4 Q/A Data Prep & Baselines\n",
    "# 60 points\n",
    "\n",
    "For assignments 4, 5, and 6 we will be exploring question answering (Q/A) using a small variant of BERT called \"BERT mini\" which is a 4-layer, 11M parameter model described here:\n",
    "\n",
    "https://huggingface.co/prajjwal1/bert-mini \n",
    "\n",
    "https://github.com/prajjwal1/generalize_lm_nli\n",
    "\n",
    "This model should be small enough to load into memory, run inference, and finetune on most laptop/desktop computers.  If you run into resource constraints in your compute environment, then you can use \"BERT tiny\" which is a 2-layer model with 4.4M parameters described here:\n",
    "\n",
    "https://huggingface.co/prajjwal1/bert-tiny\n",
    "\n",
    "In this assignment, we will focus on obtaining and preparing datasets for training and evaluation and establish a baseline Q/A that uses BERT-Mini \"out of the box\".  We are going to use three datasets for this work: \n",
    "\n",
    " * SQuAD - a publicly available Q/A dataset that is readily available and can be used without any preparation\n",
    " * Wikipedia - we will discuss this dataset in assignment 5\n",
    " * Custom Dataset - we will create a custom dataset as a class as discussed below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32839b5c-7423-4e29-aa37-2be635e24c81",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Our first step will be to import relevant python libraries including HuggingFace (transformers and datasets) and PyTorch (torch).  If you get an error when loading these libraries, then you may need to install them with a command like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d83e0fd3-c142-401e-828c-ad6c5fbfb309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (0.24.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\wilke\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92cc2f53-a40b-47ce-8421-6e5a3d7bba3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilke\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# run this block to import the necessary libraries\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import random\n",
    "from collections import Counter\n",
    "import statistics\n",
    "import json\n",
    "\n",
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ecf1cc-b47d-4032-a89e-f16ae28bdf4d",
   "metadata": {},
   "source": [
    "# SQuAD\n",
    "\n",
    "You can read about the SQuAD dataset here:\n",
    "\n",
    "https://rajpurkar.github.io/SQuAD-explorer/\n",
    "\n",
    "SQuAD consists of 87,599 training examples and 10,570 validation examples.  See for yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52658527-1a57-41f2-b94e-48f0a8cd8140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 87599\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 10570\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "squad = load_dataset(\"squad\")\n",
    "print(squad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "350a3457-d530-4d1e-ad27-5b5a0d0d00da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = len(squad['train'])\n",
    "val_count = len(squad['validation'])\n",
    "#print(f\"number of training examples: {\"{:,}\".format(train_count)}\")\n",
    "#print(f\"number of validation examples: {\"{:,}\".format(val_count)}\")\n",
    "#print(f\"total number of examples: {\"{:,}\".format(train_count+val_count)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291869b7-90c7-4ffc-95de-7d8fbea81ba3",
   "metadata": {},
   "source": [
    "## SQuAD Examples\n",
    "\n",
    "Each example has five key/value pairs for the following keys: \n",
    "* id - a unique identifier\n",
    "* title - the title of the Wikipedia article that the context passage was extracted from\n",
    "* context - a snippet of a Wikipedia article that contains the answer to the question\n",
    "* question - a question for which there is an answer that is provided by the context\n",
    "* answers - each answer has two key/value pairs corresponding to a textual answer and a character offset\n",
    "  * text - the text of the answer\n",
    "  * answer_start - the character offset where the answer text can be found in the context string.\n",
    "\n",
    "Look at some random examples from the training data by running the following code several times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46e59ba5-fa0b-43e9-bd6e-411166f9adef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '5733be284776f4190066117f', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'What is in front of the Notre Dame Main Building?', 'answers': {'text': ['a copper statue of Christ'], 'answer_start': [188]}}\n"
     ]
    }
   ],
   "source": [
    "print(squad['train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c028e425-1a37-4fd1-8953-228e2595b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(index, example):\n",
    "    print(f\"example[{index}]: id = {example['id']}\")\n",
    "    print(f\"title = {example['title']}\")\n",
    "    print(f\"context = {example['context']}\")\n",
    "    print(f\"question = {example['question']}\")\n",
    "    for answer_text in example['answers']['text']:\n",
    "        print(f\"answer = {answer_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dac3c8b8-def0-46cb-9248-b9b68c3856d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example[27085]: id = 570983a2200fba14003680f3\n",
      "title = Grape\n",
      "context = There are several sources of the seedlessness trait, and essentially all commercial cultivators get it from one of three sources: Thompson Seedless, Russian Seedless, and Black Monukka, all being cultivars of Vitis vinifera. There are currently more than a dozen varieties of seedless grapes. Several, such as Einset Seedless, Benjamin Gunnels's Prime seedless grapes, Reliance, and Venus, have been specifically cultivated for hardiness and quality in the relatively cold climates of northeastern United States and southern Ontario.\n",
      "question = How many seedless grape sources are there for commercial cultivators? \n",
      "answer = three\n"
     ]
    }
   ],
   "source": [
    "index = random.randint(0, train_count - 1)\n",
    "print_example(index, squad['train'][index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0119a1f7-b435-4fbf-92dd-b9b77d1058dd",
   "metadata": {},
   "source": [
    "## SQuAD Analysis\n",
    "Whenever you are working with a new dataset it is important to inspect it and understand what is in it.  In this section, you are asked to write code that inspects the SQuAD data to answer the following questions:\n",
    " * What are the lengths of the contexts?\n",
    " * What are the lengths of the answers?\n",
    " * How many examples have multiple answers?\n",
    "   * When there are multiple answers, are they different?\n",
    " * Is the answer text always consistent with the text found at the answer_start?\n",
    "\n",
    "I have to admit that I'm irritated by the possibility that an example could have more than one answer.  What if they are different?  How will this complicate the evaluation?  Let's run a quick sanity check first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "113814bc-ad0d-49d6-aff9-06c3bc651a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count=0\n"
     ]
    }
   ],
   "source": [
    "# how many times does an example have more than one answer?\n",
    "count = 0\n",
    "for example in squad['train']:\n",
    "    if len(example['answers']['text']) != 1:\n",
    "        count +=1\n",
    "\n",
    "print(f\"count={count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da01fb51-7eb4-493a-9d91-cafc8b6a1f9c",
   "metadata": {},
   "source": [
    "Phew!  Each example has one answer.  That simplifies our lives.  But just to be sure, let's run it again on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f40e5010-91d7-4d04-a8ff-aa892f25fd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count=10567\n"
     ]
    }
   ],
   "source": [
    "# how many times does an example have more than one answer?\n",
    "count = 0\n",
    "for example in squad['validation']:\n",
    "    if len(example['answers']['text']) != 1:\n",
    "        count +=1\n",
    "\n",
    "print(f\"count={count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68479eb2-1ff0-407a-a711-3c1c2d117a22",
   "metadata": {},
   "source": [
    "Ugh!  We have multiple answers in the validation data.  This will complicate the counting we do below and our evaluation too.  Let's look at one to understand why a question would have multiple answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee650b44-44d4-4218-9ad4-acc0bf08799a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be4db0acb8001400a502ee',\n",
       " 'title': 'Super_Bowl_50',\n",
       " 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.',\n",
       " 'question': 'Where did Super Bowl 50 take place?',\n",
       " 'answers': {'text': ['Santa Clara, California',\n",
       "   \"Levi's Stadium\",\n",
       "   \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"],\n",
       "  'answer_start': [403, 355, 355]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This example has three correct/possible answers.  This gives the model a better chance of getting an answer that is marked as correct.\n",
    "squad['validation'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2169dc9c-8701-4541-96d3-b4326e349d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's quickly verify that the first answer is a substring of the context\n",
    "context = squad['validation'][2]['context']\n",
    "answer1_text = squad['validation'][2]['answers']['text'][0]\n",
    "answer1_start = squad['validation'][2]['answers']['answer_start'][0]\n",
    "answer1_end = answer1_start + len(answer1_text)\n",
    "assert answer1_text == context[answer1_start:answer1_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43764559-5059-4890-93da-fc26c00f49fe",
   "metadata": {},
   "source": [
    "Similarly, I am irritated by the notion that perhaps the answers provided are not substrings of the contexts.  Let's do another quick sanity check to see how consistent the data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5967f9c7-d3af-4652-a07f-81d52e984ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad_answer_count = 0\n",
      "good_answer_count = 122325\n"
     ]
    }
   ],
   "source": [
    "bad_answer_count = 0\n",
    "good_answer_count = 0\n",
    "for example in list(squad['train']) + list(squad['validation']):\n",
    "    context = example['context']\n",
    "    for answer, start in zip(example['answers']['text'], example['answers']['answer_start']):\n",
    "        if answer != context[start:(start+len(answer))]:\n",
    "            print(f\"answer={answer}\")\n",
    "            print(f\"start={start}\")\n",
    "            print(f\"context[start:start+len(answer)={context[start:(start+len(answer))]}\")\n",
    "            bad_answer_count += 1\n",
    "        else:\n",
    "            good_answer_count += 1\n",
    "print(f\"bad_answer_count = {bad_answer_count}\")\n",
    "print(f\"good_answer_count = {good_answer_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62556e27-5e3f-486d-87b9-888858d782f1",
   "metadata": {},
   "source": [
    "Someone did some quality control on this dataset!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e29bb63-8c0d-4ec8-9383-16e5446034dd",
   "metadata": {},
   "source": [
    "Ok, let's answer the other questions.  First we are going to gather some basic statistics:\n",
    "\n",
    " * the lengths of the contexts in characters\n",
    " * the lengths of the contexts in tokens (white-space delimited)\n",
    " * the lengths of the answers in characters\n",
    " * the lengths of the answers in tokens (white-space delimited)\n",
    "\n",
    "Because the above four will require very similar code, we are going to avoid writing lots of redundant code by using Python lambda functions as outlined next.  A lambda function is simply a function that you can pass as a parameter to another function which can then be called by that other function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990727a3-4182-42ad-a12c-a99a0244129e",
   "metadata": {},
   "source": [
    "# TODO (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81ccca89-e0f9-4390-b3cd-003d28c5339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Please implement the following method\n",
    "\n",
    "def length_stats(examples, text_fxn, len_fxn):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    examples (dictionary): e.g. squad['train']\n",
    "    text_fxn (lambda): is a lambda function that takes an example and produces a text (e.g. a context or an answer) which we can then measure the length of\n",
    "    len_fxn (lambda): is a lambda function that takes a text and returns a count such as the length in character or the number of tokens\n",
    "\n",
    "    Returns:\n",
    "    total (int): total count for all lengths of all the texts seen\n",
    "    maximum (int): maximum length seen\n",
    "    minimum (int): minimum length seen\n",
    "    mean (float): average length \n",
    "    median (float): median length\n",
    "    mode (int): length that occurs most frequently.\n",
    "\n",
    "    Methods you might find useful are: sum, max, min, list.append, statistics.mean, statistics.median, statistics.mode\n",
    "    \"\"\"\n",
    "    text_lengths = []\n",
    "    for example in examples:\n",
    "        text = text_fxn(example)\n",
    "        length = len_fxn(text)\n",
    "        text_lengths.append(length)\n",
    "\n",
    "    minimum = min(text_lengths)\n",
    "    maximum = max(text_lengths)\n",
    "    total = sum(text_lengths)\n",
    "    mean = statistics.mean(text_lengths)\n",
    "    median = statistics.median(text_lengths)\n",
    "    mode = statistics.mode(text_lengths)\n",
    "    # the last line of the function should be equivalent to the following:\n",
    "    return total, maximum, minimum, mean, median, mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "807c65f2-016a-4b86-8f48-8ef1053c9d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This first method is implemented for you\n",
    "def compute_context_lengths_chars(examples):\n",
    "    \"\"\"\n",
    "    This method should return the total, max, min, average (mean), median, and mode of the context lengths as measured in characters.\n",
    "    Methods you might find useful are: len\n",
    "    \"\"\"\n",
    "    # this function says \"pass in an example and return its context\"\n",
    "    text_fxn = lambda example: example['context']\n",
    "    # this function says \"pass in a context and returns its length\"\n",
    "    len_fxn = lambda context: len(context)\n",
    "    return length_stats(examples, text_fxn, len_fxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8a8191f-0d68-4297-b5d9-62c146663d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method prints out the actual summary stats and then compares them with the expected values passed in.  \n",
    "def print_and_assert(length_stats_fxn, examples, description, expected_total, expected_maximum, expected_minimum, expected_mean, expected_median, expected_mode):\n",
    "    actual_total, actual_maximum, actual_minimum, actual_mean, actual_median, actual_mode = length_stats_fxn(examples)\n",
    "\n",
    "    print(f\"{description}\")\n",
    "    print(f\"total: {actual_total}\")\n",
    "    print(f\"maximum: {actual_maximum}\")\n",
    "    print(f\"minimum: {actual_minimum}\")\n",
    "    print(f\"mean: {actual_mean}\")\n",
    "    print(f\"median: {actual_median}\")\n",
    "    print(f\"mode: {actual_mode}\")\n",
    "\n",
    "    assert actual_total == expected_total\n",
    "    assert actual_maximum == expected_maximum\n",
    "    assert actual_minimum == expected_minimum\n",
    "    assert actual_mean == expected_mean\n",
    "    assert actual_median == expected_median\n",
    "    assert actual_mode == expected_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "754bb5aa-a205-4f1c-82fc-2264257e3c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length in characters of train contexts\n",
      "total: 66081551\n",
      "maximum: 3706\n",
      "minimum: 151\n",
      "mean: 754.3642164864896\n",
      "median: 693\n",
      "mode: 597\n",
      "length in characters of validation contexts\n",
      "total: 8233854\n",
      "maximum: 4063\n",
      "minimum: 157\n",
      "mean: 778.9833491012299\n",
      "median: 703.0\n",
      "mode: 631\n"
     ]
    }
   ],
   "source": [
    "# Please run the following code to check your work\n",
    "print_and_assert(compute_context_lengths_chars, squad['train'], \"length in characters of train contexts\", 66081551, 3706, 151, 754.3642164864896, 693, 597)\n",
    "#print_and_assert(compute_context_lengths_chars, squad['validation'], \"length in characters of train contexts\", 8233854, 4063, 157, 778.98334910122996, 703, 631)\n",
    "print_and_assert(compute_context_lengths_chars, squad['validation'], \"length in characters of validation contexts\", 8233854, 4063, 157, 778.98334910122996, 703, 631)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85449a3-0939-406b-8eb5-839fdb641c09",
   "metadata": {},
   "source": [
    "# TODO (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "408f9a81-5fdc-4188-bc76-4a23f096fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Please implement the following method\n",
    "\n",
    "def compute_context_lengths_tokens(examples):\n",
    "    \"\"\"\n",
    "    This method should return the total, max, min, average (mean), median, and mode of the context lengths as measured in white-space separated tokens.\n",
    "    Methods you might find useful are: len, string.split (for tokenization)\n",
    "    \"\"\"\n",
    "    text_fxn = lambda example: example['context']\n",
    "    len_fxn = lambda context: len(context.split())\n",
    "    return length_stats(examples, text_fxn, len_fxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e1c8b80-0679-430b-b1da-0d7c8ec44281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length in tokens of train contexts\n",
      "total: 10491130\n",
      "maximum: 653\n",
      "minimum: 20\n",
      "mean: 119.76312514983047\n",
      "median: 110\n",
      "mode: 87\n",
      "length in tokens of validation contexts\n",
      "total: 1310201\n",
      "maximum: 629\n",
      "minimum: 22\n",
      "mean: 123.9546830652791\n",
      "median: 112.0\n",
      "mode: 104\n"
     ]
    }
   ],
   "source": [
    "# Please run the following code to check your work\n",
    "print_and_assert(compute_context_lengths_tokens, squad['train'], \"length in tokens of train contexts\", 10491130, 653, 20, 119.76312514983047, 110, 87)\n",
    "print_and_assert(compute_context_lengths_tokens, squad['validation'], \"length in tokens of validation contexts\", 1310201, 629, 22, 123.9546830652791, 112, 104)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d11920-d23a-4082-868a-185786b44b9f",
   "metadata": {},
   "source": [
    "# TODO (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49df1d44-9fd8-470c-a008-651b332610c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Please implement the following method\n",
    "\n",
    "def compute_answer_lengths_chars(examples):\n",
    "    \"\"\"\n",
    "    This method should return the total, max, min, average (mean), median, and mode of the answer lengths as measured in characters.\n",
    "    Methods you might find useful are len\n",
    "    \"\"\"\n",
    "    text_fxn = lambda example: example['answers']['text'][0]\n",
    "    len_fxn = lambda text: len(text)\n",
    "    return length_stats(examples, text_fxn, len_fxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2b4fcac-9dc4-49c8-962b-6b6fad88fb4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length in characters of train answers\n",
      "total: 1764881\n",
      "maximum: 239\n",
      "minimum: 1\n",
      "mean: 20.147273370700578\n",
      "median: 14\n",
      "mode: 4\n",
      "length in characters of validation answers\n",
      "total: 204878\n",
      "maximum: 160\n",
      "minimum: 1\n",
      "mean: 19.382970671712393\n",
      "median: 14.0\n",
      "mode: 4\n"
     ]
    }
   ],
   "source": [
    "# Please run the following code to check your work\n",
    "print_and_assert(compute_answer_lengths_chars, squad['train'], \"length in characters of train answers\", 1764881, 239, 1, 20.147273370700578, 14, 4)\n",
    "print_and_assert(compute_answer_lengths_chars, squad['validation'], \"length in characters of validation answers\", 204878, 160, 1, 19.382970671712393, 14, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4bb730-e645-4638-96c5-297219fc5176",
   "metadata": {},
   "source": [
    "# TODO (5 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6c8ca2f-4d36-438e-9ce8-3800b972c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Please implement the following method\n",
    "\n",
    "def compute_answer_lengths_tokens(examples):\n",
    "    \"\"\"\n",
    "    This method should return the total, average (mean), median, and mode of the answer lengths as measured in characters.\n",
    "    Methods you might find useful are len, sum, list.append, statistics.mean, statistics.median, statistics.mode\n",
    "    \"\"\"\n",
    "    text_fxn = lambda example: example['answers']['text'][0]\n",
    "    len_fxn = lambda text: len(text.split())\n",
    "    return length_stats(examples, text_fxn, len_fxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2daef2df-3432-410d-8b46-8057d23863cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length in tokens of train answers\n",
      "total: 277002\n",
      "maximum: 43\n",
      "minimum: 1\n",
      "mean: 3.162159385381112\n",
      "median: 2\n",
      "mode: 1\n",
      "length in tokens of validation answers\n",
      "total: 31884\n",
      "maximum: 29\n",
      "minimum: 1\n",
      "mean: 3.016461684011353\n",
      "median: 2.0\n",
      "mode: 1\n"
     ]
    }
   ],
   "source": [
    "# Please run the following code to check your work\n",
    "print_and_assert(compute_answer_lengths_tokens, squad['train'], \"length in tokens of train answers\", 277_002, 43, 1, 3.162159385381112, 2, 1)\n",
    "print_and_assert(compute_answer_lengths_tokens, squad['validation'], \"length in tokens of validation answers\", 31_884, 29, 1, 3.016461684011353, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454d48d9-7c0c-4bb5-ba5c-4f68bc20447a",
   "metadata": {},
   "source": [
    "## SQuAD Observations\n",
    "\n",
    "This was an interesting exercise.  What did we learn?  Some of the contexts are very short - as short as 20 tokens.  Some are quite long - as much as 653 tokens. Similarly, answers can be short and long.  Some are one token long - in fact that's the most common length of an answer.  The mean answer length is significantly shorter (2 tokens) than the average length (3 tokens) which suggests that there might be a fair number long answers.  We found that the longest answer is 43 words!  Let's print out some of the long contexts and long answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "356694f0-f600-46f7-bef7-f70e158a365a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context length=695: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      "\n",
      "\n",
      "context length=1405: As at most other universities, Notre Dame's students run a number of news media outlets. The nine student-run outlets include three newspapers, both a radio and television station, and several magazines and journals. Begun as a one-page journal in September 1876, the Scholastic magazine is issued twice monthly and claims to be the oldest continuous collegiate publication in the United States. The other magazine, The Juggler, is released twice a year and focuses on student literature and artwork. The Dome yearbook is published annually. The newspapers have varying publication interests, with The Observer published daily and mainly reporting university and other news, and staffed by students from both Notre Dame and Saint Mary's College. Unlike Scholastic and The Dome, The Observer is an independent publication and does not have a faculty advisor or any editorial oversight from the University. In 1987, when some students believed that The Observer began to show a conservative bias, a liberal newspaper, Common Sense was published. Likewise, in 2003, when other students believed that the paper showed a liberal bias, the conservative paper Irish Rover went into production. Neither paper is published as often as The Observer; however, all three are distributed to all students. Finally, in Spring 2008 an undergraduate journal for political science research, Beyond Politics, made its debut.\n",
      "\n",
      "\n",
      "context length=1427: The university first offered graduate degrees, in the form of a Master of Arts (MA), in the 1854–1855 academic year. The program expanded to include Master of Laws (LL.M.) and Master of Civil Engineering in its early stages of growth, before a formal graduate school education was developed with a thesis not required to receive the degrees. This changed in 1924 with formal requirements developed for graduate degrees, including offering Doctorate (PhD) degrees. Today each of the five colleges offer graduate education. Most of the departments from the College of Arts and Letters offer PhD programs, while a professional Master of Divinity (M.Div.) program also exists. All of the departments in the College of Science offer PhD programs, except for the Department of Pre-Professional Studies. The School of Architecture offers a Master of Architecture, while each of the departments of the College of Engineering offer PhD programs. The College of Business offers multiple professional programs including MBA and Master of Science in Accountancy programs. It also operates facilities in Chicago and Cincinnati for its executive MBA program. Additionally, the Alliance for Catholic Education program offers a Master of Education program where students study at the university during the summer and teach in Catholic elementary schools, middle schools, and high schools across the Southern United States for two school years.\n",
      "\n",
      "\n",
      "context length=1626: In 2014 the Notre Dame student body consisted of 12,179 students, with 8,448 undergraduates, 2,138 graduate and professional and 1,593 professional (Law, M.Div., Business, M.Ed.) students. Around 21–24% of students are children of alumni, and although 37% of students come from the Midwestern United States, the student body represents all 50 states and 100 countries. As of March 2007[update] The Princeton Review ranked the school as the fifth highest 'dream school' for parents to send their children. As of March 2015[update] The Princeton Review ranked Notre Dame as the ninth highest. The school has been previously criticized for its lack of diversity, and The Princeton Review ranks the university highly among schools at which \"Alternative Lifestyles [are] Not an Alternative.\" It has also been commended by some diversity oriented publications; Hispanic Magazine in 2004 ranked the university ninth on its list of the top–25 colleges for Latinos, and The Journal of Blacks in Higher Education recognized the university in 2006 for raising enrollment of African-American students. With 6,000 participants, the university's intramural sports program was named in 2004 by Sports Illustrated as the best program in the country, while in 2007 The Princeton Review named it as the top school where \"Everyone Plays Intramural Sports.\" The annual Bookstore Basketball tournament is the largest outdoor five-on-five tournament in the world with over 700 teams participating each year, while the Notre Dame Men's Boxing Club hosts the annual Bengal Bouts tournament that raises money for the Holy Cross Missions in Bangladesh.\n",
      "\n",
      "\n",
      "context length=1786: Since the construction of its oldest buildings, the university's physical plant has grown substantially. Over the years 29 residence halls have been built to accommodate students and each has been constructed with its own chapel. Many academic building were added together with a system of libraries, the most prominent of which is the Theodore Hesburgh Library, built in 1963 and today containing almost 4 million books. Since 2004, several buildings have been added, including the DeBartolo Performing Arts Center, the Guglielmino Complex, and the Jordan Hall of Science. Additionally, a new residence for men, Duncan Hall, was begun on March 8, 2007, and began accepting residents for the Fall 2008 semester. Ryan Hall was completed and began housing undergraduate women in the fall of 2009. A new engineering building, Stinson-Remick Hall, a new combination Center for Social Concerns/Institute for Church Life building, Geddes Hall, and a law school addition have recently been completed as well. Additionally the new hockey arena opened in the fall of 2011. The Stayer Center for Executive Education, which houses the Mendoza College of Business Executive Education Department opened in March 2013 just South of the Mendoza College of Business building. Because of its long athletic tradition, the university features also many building dedicated to sport. The most famous is Notre Dame Stadium, home of the Fighting Irish football team; it has been renovated several times and today it can hold more than 80 thousand people. Prominent venues include also the Edmund P. Joyce Center, with indoor basketball and volleyball courts, and the Compton Family Ice Arena, a two-rink facility dedicated to hockey. Also, there are many outdoor fields, as the Frank Eck Stadium for baseball.\n",
      "\n",
      "\n",
      "context length=1895: On April 4, 2008, Beyoncé married Jay Z. She publicly revealed their marriage in a video montage at the listening party for her third studio album, I Am... Sasha Fierce, in Manhattan's Sony Club on October 22, 2008. I Am... Sasha Fierce was released on November 18, 2008 in the United States. The album formally introduces Beyoncé's alter ego Sasha Fierce, conceived during the making of her 2003 single \"Crazy in Love\", selling 482,000 copies in its first week, debuting atop the Billboard 200, and giving Beyoncé her third consecutive number-one album in the US. The album featured the number-one song \"Single Ladies (Put a Ring on It)\" and the top-five songs \"If I Were a Boy\" and \"Halo\". Achieving the accomplishment of becoming her longest-running Hot 100 single in her career, \"Halo\"'s success in the US helped Beyoncé attain more top-ten singles on the list than any other woman during the 2000s. It also included the successful \"Sweet Dreams\", and singles \"Diva\", \"Ego\", \"Broken-Hearted Girl\" and \"Video Phone\". The music video for \"Single Ladies\" has been parodied and imitated around the world, spawning the \"first major dance craze\" of the Internet age according to the Toronto Star. The video has won several awards, including Best Video at the 2009 MTV Europe Music Awards, the 2009 Scottish MOBO Awards, and the 2009 BET Awards. At the 2009 MTV Video Music Awards, the video was nominated for nine awards, ultimately winning three including Video of the Year. Its failure to win the Best Female Video category, which went to American country pop singer Taylor Swift's \"You Belong with Me\", led to Kanye West interrupting the ceremony and Beyoncé improvising a re-presentation of Swift's award during her own acceptance speech. In March 2009, Beyoncé embarked on the I Am... World Tour, her second headlining worldwide concert tour, consisting of 108 shows, grossing $119.5 million.\n",
      "\n",
      "\n",
      "context length=1999: The Montana Territory was formed on April 26, 1864, when the U.S. passed the Organic Act. Schools started forming in the area before it was officially a territory as families started settling into the area. The first schools were subscription schools that typically held in the teacher's home. The first formal school on record was at Fort Owen in Bitterroot valley in 1862. The students were Indian children and the children of Fort Owen employees. The first school term started in early winter and only lasted until February 28. Classes were taught by Mr. Robinson. Another early subscription school was started by Thomas Dimsdale in Virginia City in 1863. In this school students were charged $1.75 per week. The Montana Territorial Legislative Assembly had its inaugural meeting in 1864. The first legislature authorized counties to levy taxes for schools, which set the foundations for public schooling. Madison County was the first to take advantage of the newly authorized taxes and it formed fhe first public school in Virginia City in 1886. The first school year was scheduled to begin in January 1866, but severe weather postponed its opening until March. The first school year ran through the summer and didn't end until August 17. One of the first teachers at the school was Sarah Raymond. She was a 25-year-old woman who had traveled to Virginia City via wagon train in 1865. To become a certified teacher, Raymond took a test in her home and paid a $6 fee in gold dust to obtain a teaching certificate. With the help of an assistant teacher, Mrs. Farley, Raymond was responsible for teaching 50 to 60 students each day out of the 81 students enrolled at the school. Sarah Raymond was paid at a rate of $125 per month, and Mrs. Farley was paid $75 per month. There were no textbooks used in the school. In their place was an assortment of books brought in by various emigrants. Sarah quit teaching the following year, but would later become the Madison County superintendent of schools.\n",
      "\n",
      "\n",
      "context length=2132: Van Praag states that the Ming court established diplomatic delegations with Tibet merely to secure urgently needed horses. Wang and Nyima argue that these were not diplomatic delegations at all, that Tibetan areas were ruled by the Ming since Tibetan leaders were granted positions as Ming officials, that horses were collected from Tibet as a mandatory \"corvée\" tax, and therefore Tibetans were \"undertaking domestic affairs, not foreign diplomacy\". Sperling writes that the Ming simultaneously bought horses in the Kham region while fighting Tibetan tribes in Amdo and receiving Tibetan embassies in Nanjing. He also argues that the embassies of Tibetan lamas visiting the Ming court were for the most part efforts to promote commercial transactions between the lamas' large, wealthy entourage and Ming Chinese merchants and officials. Kolmaš writes that while the Ming maintained a laissez-faire policy towards Tibet and limited the numbers of the Tibetan retinues, the Tibetans sought to maintain a tributary relationship with the Ming because imperial patronage provided them with wealth and power. Laird writes that Tibetans eagerly sought Ming court invitations since the gifts the Tibetans received for bringing tribute were much greater in value than the latter. As for the Yongle Emperor's gifts to his Tibetan and Nepalese vassals such as silver wares, Buddha relics, utensils for Buddhist temples and religious ceremonies, and gowns and robes for monks, Tsai writes \"in his effort to draw neighboring states to the Ming orbit so that he could bask in glory, the Yongle Emperor was quite willing to pay a small price\". The Information Office of the State Council of the PRC lists the Tibetan tribute items as oxen, horses, camels, sheep, fur products, medical herbs, Tibetan incenses, thangkas (painted scrolls), and handicrafts; while the Ming awarded Tibetan tribute-bearers an equal value of gold, silver, satin and brocade, bolts of cloth, grains, and tea leaves. Silk workshops during the Ming also catered specifically to the Tibetan market with silk clothes and furnishings featuring Tibetan Buddhist iconography.\n",
      "\n",
      "\n",
      "context length=3076: Critical appraisal of the film was mixed in the United States. In a lukewarm review for RogerEbert.com, Matt Zoller Seitz gave the film 2.5 stars out of 4, describing Spectre as inconsistent and unable to capitalise on its potential. Kenneth Turan, reviewing the film for Los Angeles Times, concluded that Spectre \"comes off as exhausted and uninspired\". Manohla Dargis of The New York Times panned the film as having \"nothing surprising\" and sacrificing its originality for the sake of box office returns. Forbes' Scott Mendelson also heavily criticised the film, denouncing Spectre as \"the worst 007 movie in 30 years\". Darren Franich of Entertainment Weekly viewed Spectre as \"an overreaction to our current blockbuster moment\", aspiring \"to be a serialized sequel\" and proving \"itself as a Saga\". While noting that \"[n]othing that happens in Spectre holds up to even minor logical scrutiny\", he had \"come not to bury Spectre, but to weirdly praise it. Because the final act of the movie is so strange, so willfully obtuse, that it deserves extra attention.\" In a positive review Rolling Stone, Peter Travers gave the film 3.5 stars out of 4, describing \"The 24th movie about the British MI6 agent with a license to kill is party time for Bond fans, a fierce, funny, gorgeously produced valentine to the longest-running franchise in movies\". Other positive reviews from Mick LaSalle from the San Francisco Chronicle, gave it a perfect 100 score, stating: “One of the great satisfactions of Spectre is that, in addition to all the stirring action, and all the timely references to a secret organization out to steal everyone’s personal information, we get to believe in Bond as a person.” Stephen Whitty from the New York Daily News, gave it an 80 grade, saying: “Craig is cruelly efficient. Dave Bautista makes a good, Oddjob-like assassin. And while Lea Seydoux doesn’t leave a huge impression as this film’s “Bond girl,” perhaps it’s because we’ve already met — far too briefly — the hypnotic Monica Bellucci, as the first real “Bond woman” since Diana Rigg.” Richard Roeper from the Chicago Sun-Times, gave it a 75 grade. He stated: “This is the 24th Bond film and it ranks solidly in the middle of the all-time rankings, which means it’s still a slick, beautifully photographed, action-packed, international thriller with a number of wonderfully, ludicrously entertaining set pieces, a sprinkling of dry wit, myriad gorgeous women and a classic psycho-villain who is clearly out of his mind but seems to like it that way.” Michael Phillips over at the Chicago Tribune, gave it a 75 grade. He stated: “For all its workmanlike devotion to out-of-control helicopters, “Spectre” works best when everyone’s on the ground, doing his or her job, driving expensive fast cars heedlessly, detonating the occasional wisecrack, enjoying themselves and their beautiful clothes.” Guy Lodge from Variety, gave it a 70 score, stating: “What’s missing is the unexpected emotional urgency of “Skyfall,” as the film sustains its predecessor’s nostalgia kick with a less sentimental bent.”\n",
      "\n",
      "\n",
      "context length=3385: Original master discs are created by lathe-cutting: a lathe is used to cut a modulated groove into a blank record. The blank records for cutting used to be cooked up, as needed, by the cutting engineer, using what Robert K. Morrison describes as a \"metallic soap,\" containing lead litharge, ozokerite, barium sulfate, montan wax, stearin and paraffin, among other ingredients. Cut \"wax\" sound discs would be placed in a vacuum chamber and gold-sputtered to make them electrically conductive for use as mandrels in an electroforming bath, where pressing stamper parts were made. Later, the French company Pyral invented a ready-made blank disc having a thin nitro-cellulose lacquer coating (approximately 7 mils thickness on both sides) that was applied to an aluminum substrate. Lacquer cuts result in an immediately playable, or processable, master record. If vinyl pressings are wanted, the still-unplayed sound disc is used as a mandrel for electroforming nickel records that are used for manufacturing pressing stampers. The electroformed nickel records are mechanically separated from their respective mandrels. This is done with relative ease because no actual \"plating\" of the mandrel occurs in the type of electrodeposition known as electroforming, unlike with electroplating, in which the adhesion of the new phase of metal is chemical and relatively permanent. The one-molecule-thick coating of silver (that was sprayed onto the processed lacquer sound disc in order to make its surface electrically conductive) reverse-plates onto the nickel record's face. This negative impression disc (having ridges in place of grooves) is known as a nickel master, \"matrix\" or \"father.\" The \"father\" is then used as a mandrel to electroform a positive disc known as a \"mother\". Many mothers can be grown on a single \"father\" before ridges deteriorate beyond effective use. The \"mothers\" are then used as mandrels for electroforming more negative discs known as \"sons\". Each \"mother\" can be used to make many \"sons\" before deteriorating. The \"sons\" are then converted into \"stampers\" by center-punching a spindle hole (which was lost from the lacquer sound disc during initial electroforming of the \"father\"), and by custom-forming the target pressing profile. This allows them to be placed in the dies of the target (make and model) record press and, by center-roughing, to facilitate the adhesion of the label, which gets stuck onto the vinyl pressing without any glue. In this way, several million vinyl discs can be produced from a single lacquer sound disc. When only a few hundred discs are required, instead of electroforming a \"son\" (for each side), the \"father\" is removed of its silver and converted into a stamper. Production by this latter method, known as the \"two-step-process\" (as it does not entail creation of \"sons\" but does involve creation of \"mothers,\" which are used for test playing and kept as \"safeties\" for electroforming future \"sons\") is limited to a few hundred vinyl pressings. The pressing count can increase if the stamper holds out and the quality of the vinyl is high. The \"sons\" made during a \"three-step\" electroforming make better stampers since they don't require silver removal (which reduces some high fidelity because of etching erasing part of the smallest groove modulations) and also because they have a stronger metal structure than \"fathers\".\n",
      "\n",
      "\n",
      "context length=3706: The sky is usually clear above the desert and the sunshine duration is extremely high everywhere in the Sahara. Most of the desert enjoys more than 3,600 h of bright sunshine annually or over 82% of the time and a wide area in the eastern part experiences in excess of 4,000 h of bright sunshine a year or over 91% of the time, and the highest values are very close to the theoretical maximum value. A value of 4,300 h or 98% of the time would be recorded in Upper Egypt (Aswan, Luxor) and in the Nubian Desert (Wadi Halfa). The annual average direct solar irradiation is around 2,800 kWh/(m2 year) in the Great Desert. The Sahara has a huge potential for solar energy production. The constantly high position of the sun, the extremely low relative humidity, the lack of vegetation and rainfall make the Great Desert the hottest continuously large area worldwide and certainly the hottest place on Earth during summertime in some spots. The average high temperature exceeds 38 °C (100.4 °F) - 40 °C (104 °F) during the hottest month nearly everywhere in the desert except at very high mountainous areas. The highest officially recorded average high temperature was 47 °C (116.6 °F) in a remote desert town in the Algerian Desert called Bou Bernous with an elevation of 378 meters above sea level. It's the world's highest recorded average high temperature and only Death Valley, California rivals it. Other hot spots in Algeria such as Adrar, Timimoun, In Salah, Ouallene, Aoulef, Reggane with an elevation between 200 and 400 meters above sea level get slightly lower summer average highs around 46 °C (114.8 °F) during the hottest months of the year. Salah, well known in Algeria for its extreme heat, has an average high temperature of 43.8 °C (110.8 °F), 46.4 °C (115.5 °F), 45.5 (113.9 °F). Furthermore, 41.9 °C (107.4 °F) in June, July, August and September. In fact, there are even hotter spots in the Sahara, but they are located in extremely remote areas, especially in the Azalai, lying in northern Mali. The major part of the desert experiences around 3 – 5 months when the average high strictly exceeds 40 °C (104 °F). The southern central part of the desert experiences up to 6 – 7 months when the average high temperature strictly exceeds 40 °C (104 °F) which shows the constancy and the length of the really hot season in the Sahara. Some examples of this are Bilma, Niger and Faya-Largeau, Chad. The annual average daily temperature exceeds 20 °C (68 °F) everywhere and can approach 30 °C (86 °F) in the hottest regions year-round. However, most of the desert has a value in excess of 25 °C (77 °F). The sand and ground temperatures are even more extreme. During daytime, the sand temperature is extremely high as it can easily reach 80 °C (176 °F) or more. A sand temperature of 83.5 °C (182.3 °F) has been recorded in Port Sudan. Ground temperatures of 72 °C (161.6 °F) have been recorded in the Adrar of Mauritania and a value of 75 °C (167 °F) has been measured in Borkou, northern Chad. Due to lack of cloud cover and very low humidity, the desert usually features high diurnal temperature variations between days and nights. However, it's a myth that the nights are cold after extremely hot days in the Sahara. The average diurnal temperature range is typically between 13 °C (55.4 °F) and 20 °C (68 °F). The lowest values are found along the coastal regions due to high humidity and are often even lower than 10 °C (50 °F), while the highest values are found in inland desert areas where the humidity is the lowest, mainly in the southern Sahara. Still, it's true that winter nights can be cold as it can drop to the freezing point and even below, especially in high-elevation areas.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if the current context is the longest we've seen thus far, then print it out\n",
    "max_length = 0\n",
    "for example in squad['train']:\n",
    "    context_len = len(example['context'])\n",
    "    if context_len > max_length:\n",
    "        max_length = context_len\n",
    "        print(f\"context length={context_len}: {example['context']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1988e84a-41b9-41d0-89ed-dbdfedde5a34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer length=26: Saint Bernadette Soubirous\n",
      "\n",
      "answer length=39: a Marian place of prayer and reflection\n",
      "\n",
      "answer length=54: Joan B. Kroc Institute for International Peace Studies\n",
      "\n",
      "answer length=67: oldest university band in continuous existence in the United States\n",
      "\n",
      "answer length=71: American Society of Composers, Authors, and Publishers Pop Music Awards\n",
      "\n",
      "answer length=76: the American Society of Composers, Authors, and Publishers Pop Music Awards.\n",
      "\n",
      "answer length=98: sportswear, denim offerings with fur, outerwear and accessories that include handbags and footwear\n",
      "\n",
      "answer length=128: The word genocide is the combination of the Greek prefix geno- (meaning tribe or race) and caedere (the Latin word for to kill).\n",
      "\n",
      "answer length=153: a specific set of violent crimes that are committed against a certain group with the attempt to remove the entire group from existence or to destroy them\n",
      "\n",
      "answer length=239: that the sudden shift of a huge quantity of water into the region could have relaxed the tension between the two sides of the fault, allowing them to move apart, and could have increased the direct pressure on it, causing a violent rupture\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if the current answer is the longest we've seen thus far, then print it out\n",
    "max_length = 0\n",
    "for example in squad['train']:\n",
    "    context_len = len(example['answers']['text'][0])\n",
    "    if context_len > max_length:\n",
    "        max_length = context_len\n",
    "        print(f\"answer length={context_len}: {example['answers']['text'][0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33477431-6543-4e45-ae0d-1c7d555a1059",
   "metadata": {},
   "source": [
    "# Custom Dataset\n",
    "\n",
    "We are going to create a custom Q/A dataset by having every student create 10 question / answer pairs in English.  If everyone creates 10 examples, then we should have a new corpus of Q/A pairs with over 500 examples.  There is no plan to release this data outside of this class, so we are not going to be particularly careful about how we gather data for this corpus.  Please use good judgment and use resources that are widely available.  Each example should have the following fields:\n",
    "\n",
    " * context - you can copy some span of text that contains the answer for the question\n",
    " * question - please compose a new question that is based on the context and whose answer is provided in the context\n",
    " * answers - these should correspond to spans of text found in the context\n",
    " * source - this should be a link that when visited, you should be able to see the text of the context somewhere on the screen.\n",
    "\n",
    "There are many sources of widely available data including various news outlets, GitHub, [Project Gutenberg](https://www.gutenberg.org), [EDGAR](https://www.sec.gov/search-filings), [PubMed](https://pubmed.ncbi.nlm.nih.gov/), [arXiv](https://arxiv.org/), [IMDB](https://www.imdb.com/), etc.  Please do not use StackExchange or other websites built around questions and answers.  Also, please avoid social media sites such as X, Facebook, etc.  Please try to create question and answer pairs that are suitable for this learning task.  Please look at the SQuAD data for examples if you need some sense of what they should look like.  \n",
    "\n",
    "Please create 10 question/answer examples and format them using the following code and then submit them to me as `your-name.jsonl`.  Everyone in class will be able to see all questions submitted, but no one will know which questions you contributed.\n",
    "\n",
    "When all the examples have been submitted I will create a new dataset from each jsonl file and distribute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3248454-085d-44f2-a6d2-7d7d91ab4084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_example(context, question, answers, source):\n",
    "    if len(answers) != len(set(answers)):\n",
    "        raise ValueError(f\"Invalid answers: each answer must be unique.\")\n",
    "    qa = {'context':context, 'question':question, 'source':source}\n",
    "    answer_starts = []\n",
    "    for answer in answers:\n",
    "        answer_start = context.find(answer)\n",
    "        if answer_start >= 0:\n",
    "            answer_starts.append(answer_start)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid answer: {answer}. The answer must be a substring of the context.\")\n",
    "    qa['answers'] = {'text':answers, 'answer_start':answer_starts}  \n",
    "    return qa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f56e6a-1c39-4e07-ae1a-046de456de24",
   "metadata": {},
   "source": [
    "# TODO (20 Points)\n",
    "\n",
    "Please email me the resulting jsonl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbb3e2f2-3066-469a-b548-1f186aaeb371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO please create 10 blocks of code corresponding to 10 question answer pairs.  \n",
    "context1 = \"Surf's Up is a 2007 American animated mockumentary comedy film produced by Columbia Pictures and Sony Pictures Animation, and distributed by Sony Pictures Releasing. It was directed by Ash Brannon and Chris Buck from a screenplay they co-wrote with Don Rhymer and producer Chris Jenkins, based on a story by Jenkins and Christian Darren. The film stars the voices of Shia LaBeouf, Jeff Bridges, Zooey Deschanel, Jon Heder, and James Woods. It is a parody of surfing documentaries, such as The Endless Summer and Riding Giants, with parts of the plot parodying North Shore.\"\n",
    "question1 = \"What year was Surf's Up released?\"\n",
    "answers1 = [\"2007\"]\n",
    "source1 = \"https://en.wikipedia.org/wiki/Surf's_Up_(film)\"\n",
    "\n",
    "context2 = \"McDonald's Corporation, doing business as McDonald's, is an American multinational fast food chain, founded in 1940 as a restaurant operated by Richard and Maurice McDonald, in San Bernardino, California, United States. They rechristened their business as a hamburger stand and later turned the company into a franchise, with the Golden Arches logo being introduced in 1953 at a location in Phoenix, Arizona.\"\n",
    "question2 = \"Where were the Gold Arches first introduced?\"\n",
    "answers2 = [\"Phoenix, Arizona\"]\n",
    "source2 = \"https://en.wikipedia.org/wiki/McDonald%27s\"\n",
    "\n",
    "context3 = \"Darien (formerly Cass) is a city in DuPage County, Illinois, United States. Per the 2020 census, the population was 22,011. A southwestern suburb of Chicago, Darien was named after the town of Darien, Connecticut. Darien is just north of I-55 and Historic U.S. Route 66 (now Frontage Road). The entire south edge of the town borders Waterfall Glen.\"\n",
    "question3 = \"What is the population of Darien?\"\n",
    "answers3 = [\"22,011\"]\n",
    "source3 = \"https://en.wikipedia.org/wiki/Darien,_Illinois\"\n",
    "\n",
    "context4 = \"A synthesizer (also synthesiser or synth) is an electronic musical instrument that generates audio signals. Synthesizers typically create sounds by generating waveforms through methods including subtractive synthesis, additive synthesis and frequency modulation synthesis. These sounds may be altered by components such as filters, which cut or boost frequencies; envelopes, which control articulation, or how notes begin and end; and low-frequency oscillators, which modulate parameters such as pitch, volume, or filter characteristics affecting timbre. Synthesizers are typically played with keyboards or controlled by sequencers, software or other instruments, and may be synchronized to other equipment via MIDI.\"\n",
    "question4 = \"What do pitch, volume or filter characteristics affect?\"\n",
    "answers4 = [\"timbre\"]\n",
    "source4 = \"https://en.wikipedia.org/wiki/Synthesizer\"\n",
    "\n",
    "context5 = \"Temple University (Temple or TU) is a public state-related research university in Philadelphia, Pennsylvania. It was founded in 1884 by the Baptist minister Russell Conwell and his congregation Grace Baptist Church of Philadelphia then called Baptist Temple.\"\n",
    "question5 = \"Who founded Temple University?\"\n",
    "answers5 = [\"Russell Conwell\"]\n",
    "source5 = \"https://en.wikipedia.org/wiki/Temple_University\"\n",
    "\n",
    "context6 = \"Footloose is a 1984 American musical drama film directed by Herbert Ross and written by Dean Pitchford. It tells the story of Ren McCormack (Kevin Bacon), a teenager from Chicago who moves to a small town, where he attempts to overturn the ban on dancing instituted by the efforts of a local minister (John Lithgow). The film was released on February 17, 1984, by Paramount Pictures, and received mixed reviews from the critics and was a box office success, grossing $80 million in North America, becoming the seventh highest-grossing film of 1984. The songs Footloose by Kenny Loggins and Let's Hear It for the Boy by Deniece Williams were nominated for the Academy Award for Best Original Song.\"\n",
    "question6 = \"What were songs Footloose and Let's Hear It for the Boy nominated for?\"\n",
    "answers6 = [\"the Academy Award for Best Original Song\"]\n",
    "source6 = \"https://en.wikipedia.org/wiki/Footloose\"\n",
    "\n",
    "context7 = \"Jennifer Shrader Lawrence (born August 15, 1990) is an American actress and producer. Lawrence is known for starring in both action film franchises and independent dramas, and her films have grossed over $6 billion worldwide. The world's highest-paid actress in 2015 and 2016, she appeared in Time's 100 most influential people in the world list in 2013 and the Forbes Celebrity 100 list from 2013 to 2016.\"\n",
    "question7 = \"What year was Jennifer Lawrence born?\"\n",
    "answers7 = [\"1990\"]\n",
    "source7 = \"https://en.wikipedia.org/wiki/Jennifer_Lawrence\"\n",
    "\n",
    "context8 = \"The six classes of British nationality each have varying degrees of civil and political rights, due to the UK's historical status as a colonial empire. The principal class of British nationality is British citizenship, which is associated with the British Islands. British nationals associated with an overseas territory are British Overseas Territories citizens (BOTCs). Almost all BOTCs (except for those from Akrotiri and Dhekelia) have also been British citizens since 2002. Individuals connected with former British colonies may hold residual forms of British nationality, which do not confer an automatic right of abode in the United Kingdom and generally may no longer be acquired. These residual nationalities are the statuses of British Overseas citizen, British subject, British National (Overseas), and British protected person.\"\n",
    "question8 = \"What class of British nationality are British nationals associated with overseas territory?\"\n",
    "answers8 = [\"British Overseas Territories citizens (BOTCs)\"]\n",
    "source8 = \"https://en.wikipedia.org/wiki/British_nationality_law\"\n",
    "\n",
    "context9 = \"The Ireland Act 1949 is an Act of the Parliament of the United Kingdom intended to deal with the consequences of the Republic of Ireland Act 1948 as passed by the Irish parliament, the Oireachtas. Following the secession of most of Ireland from the United Kingdom in 1922, the then created Irish Free State remained (for the purposes of British law) a dominion of the British Empire and thus its people remained British subjects with the right to live and work in the United Kingdom and elsewhere in the Empire. The British monarch continued to be head of state.\"\n",
    "question9 = \"What is the Irish Parlament called?\"\n",
    "answers9 = [\"the Oireachtas\"]\n",
    "source9 = \"https://en.wikipedia.org/wiki/Ireland_Act_1949\"\n",
    "\n",
    "context10 = \"New York University (NYU) is a private research university in New York City, United States. Chartered in 1831 by the New York State Legislature, NYU was founded in 1832 by Albert Gallatin as a non-denominational all-male institution near City Hall based on a curriculum focused on a secular education. The university moved in 1833 and has maintained its main campus in Greenwich Village surrounding Washington Square Park. Since then, the university has added an engineering school in Brooklyn's MetroTech Center and graduate schools throughout Manhattan.\"\n",
    "question10 = \"When did New York University move?\"\n",
    "answers10 = [\"1833\"]\n",
    "source10 = \"https://en.wikipedia.org/wiki/New_York_University\"\n",
    "\n",
    "# repeat until you have 10 blocks of four variables \n",
    "\n",
    "qa1 = to_example(context1, question1, answers1, source1)\n",
    "qa2 = to_example(context2, question2, answers2, source2)\n",
    "qa3 = to_example(context3, question3, answers3, source3)\n",
    "qa4 = to_example(context4, question4, answers4, source4)\n",
    "qa5 = to_example(context5, question5, answers5, source5)\n",
    "qa6 = to_example(context6, question6, answers6, source6)\n",
    "qa7 = to_example(context7, question7, answers7, source7)\n",
    "qa8 = to_example(context8, question8, answers8, source8)\n",
    "qa9 = to_example(context9, question9, answers9, source9)\n",
    "qa10 = to_example(context10, question10, answers10, source10)\n",
    "\n",
    "qas = [qa1, qa2, qa3, qa4, qa5, qa6, qa7, qa8, qa9, qa10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdef79c9-6160-4b7d-9e40-42fc3af160f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"jasper.wilkerson.jsonl\" # edit this line to use your name\n",
    "\n",
    "with open(out_path, 'w') as jsonl:\n",
    "    for qa in qas:\n",
    "        print(json.dumps(qa), file=jsonl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309fca1-6f95-4f9e-b1b7-ddc5ba5637b3",
   "metadata": {},
   "source": [
    "# BERT-Mini\n",
    "\n",
    "We will be using a small version the BERT called \"BERT mini\" which is a 4-layer, 11M parameter model described here:\n",
    "\n",
    "https://huggingface.co/prajjwal1/bert-mini\n",
    "\n",
    "https://github.com/prajjwal1/generalize_lm_nli\n",
    "\n",
    "If you find that your compute device (i.e. laptop or desktop or server) does not have enough resources to use \"BERT mini\", then please give \"BERT tiny\" a try.  \n",
    "\n",
    "Let's start by loading the model and the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfdae33b-e236-4665-8c5f-d19bf5dc93b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilke\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at prajjwal1/bert-mini and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('prajjwal1/bert-mini')\n",
    "model = BertForQuestionAnswering.from_pretrained('prajjwal1/bert-mini')\n",
    "\n",
    "# if you need to use BERT tiny, then comment the code above and uncomment the code below\n",
    "# tokenizer = BertTokenizer.from_pretrained('prajjwal1/bert-tiny')\n",
    "# model = BertForQuestionAnswering.from_pretrained('prajjwal1/bert-tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "878d3537-3336-430e-8ce8-bccde9ac0fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 11105282\n",
      "Trainable parameters: 11105282\n"
     ]
    }
   ],
   "source": [
    "# Please run the following to get some sense of what is in BERT Mini\n",
    "# Count the total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# Count the number of trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb78d6b-e774-4136-979a-d9fcd0e3afde",
   "metadata": {},
   "source": [
    "## Answer one question\n",
    "\n",
    "Let's try to get BERT Mini to answer a single question from SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a50eb515-9c83-4207-8b24-e9d40878bc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example: question = 'After Findlay's charting how many islands of the group were named Ellice?', context = 'The next European to visit was Arent Schuyler de Peyster, of New York, captain of the armed brigantine or privateer Rebecca, sailing under British colours, which passed through the southern Tuvaluan waters in May 1819; de Peyster sighted Nukufetau and Funafuti, which he named Ellice's Island after an English Politician, Edward Ellice, the Member of Parliament for Coventry and the owner of the Rebecca's cargo. The name Ellice was applied to all nine islands after the work of English hydrographer Alexander George Findlay.'\n",
      "expected answer = all nine islands\n"
     ]
    }
   ],
   "source": [
    "# first let's grab a random training example\n",
    "index = random.randint(0, train_count - 1)\n",
    "example = squad['train'][index]\n",
    "question = example['question']\n",
    "context = example['context']\n",
    "print(f\"example: question = '{question}', context = '{context}'\")\n",
    "print(f\"expected answer = {example['answers']['text'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8defd52-5dc5-4477-9518-cd1ea5f12da3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2044,  2424,  8485,  1005,  1055, 17918,  2129,  2116,  3470,\n",
      "          1997,  1996,  2177,  2020,  2315,  3449, 13231,  1029,   102,  1996,\n",
      "          2279,  2647,  2000,  3942,  2001,  4995,  2102,  8040,  6979, 20853,\n",
      "          2139, 21877, 27268,  2121,  1010,  1997,  2047,  2259,  1010,  2952,\n",
      "          1997,  1996,  4273, 16908,  4630,  3170,  2030, 26790,  9423,  1010,\n",
      "          8354,  2104,  2329,  8604,  1010,  2029,  2979,  2083,  1996,  2670,\n",
      "         10722, 10175, 13860,  5380,  1999,  2089, 12552,  1025,  2139, 21877,\n",
      "         27268,  2121, 19985, 16371,  5283,  7959,  2696,  2226,  1998,  4569,\n",
      "         10354, 21823,  1010,  2029,  2002,  2315,  3449, 13231,  1005,  1055,\n",
      "          2479,  2044,  2019,  2394,  3761,  1010,  3487,  3449, 13231,  1010,\n",
      "          1996,  2266,  1997,  3323,  2005, 13613,  1998,  1996,  3954,  1997,\n",
      "          1996,  9423,  1005,  1055,  6636,  1012,  1996,  2171,  3449, 13231,\n",
      "          2001,  4162,  2000,  2035,  3157,  3470,  2044,  1996,  2147,  1997,\n",
      "          2394, 18479, 18657,  3656,  2577,  2424,  8485,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# tokenize the question and the context and inspect the results\n",
    "inputs = tokenizer(question, context, return_tensors='pt')\n",
    "input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "757be48c-250c-4ddc-8a4d-e8def9f29fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the special tokens at the beginning and end are [CLS] [SEP]\n",
      "token id for 'Who' is 2040\n",
      "token for '2079' is do\n"
     ]
    }
   ],
   "source": [
    "# observe that the input ids begin with 101 and end with 102 for every example you observe\n",
    "# these are special tokens '[CLS]' and '[SEP'].  You will observe there is always a 102 between the question token ids and the context token ids.\n",
    "# also observe that the token type ids assign 0 to the question tokens and 1 to the context tokens.\n",
    "special = tokenizer.decode([101, 102])\n",
    "print(f\"the special tokens at the beginning and end are {special}\")\n",
    "\n",
    "# you can decode any token id or encode any token to get some sense of how the tokenization works\n",
    "\n",
    "token_id = tokenizer.encode(\"Who\", add_special_tokens=False)[0]\n",
    "print(f\"token id for 'Who' is {token_id}\")\n",
    "\n",
    "token = tokenizer.decode([2079])\n",
    "print(f\"token for '2079' is {token}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687440d8-cb84-430a-839f-ade858dc0e50",
   "metadata": {},
   "source": [
    "ok - let's call the model.  There are many ways to use a BERT model.  Here we have instantiated BERT as a BertForQuestionAnswering object.  You can read about this here:\n",
    "\n",
    "https://huggingface.co/transformers/v3.0.2/model_doc/bert.html#bertforquestionanswering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "915d99fb-1837-4408-9f95-440966bb46b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1161,  0.1602,  0.4311,  0.3323,  0.3339, -0.0034,  0.3245,  0.4651,\n",
      "          0.2019,  0.2221,  0.1454,  0.2009,  0.1181,  0.0544, -0.0920,  0.0696,\n",
      "          0.1881,  0.1520,  0.0133,  0.2852,  0.0325,  0.1468, -0.2346, -0.2170,\n",
      "          0.2616,  0.1069,  0.3365,  0.0863,  0.1668,  0.3600,  0.0614,  0.4924,\n",
      "          0.1830,  0.0598,  0.0162,  0.2512,  0.2964, -0.2163, -0.0877, -0.0626,\n",
      "          0.3703,  0.2311,  0.0493, -0.0461,  0.3656, -0.0251, -0.1655,  0.1667,\n",
      "         -0.1079, -0.2763,  0.0054,  0.0110, -0.0685, -0.2000, -0.1252, -0.0144,\n",
      "          0.2877,  0.1901,  0.3239,  0.2435,  0.4178,  0.1285,  0.3391, -0.1707,\n",
      "         -0.1915, -0.2611, -0.1546, -0.0116,  0.3176,  0.5169,  0.2286,  0.1285,\n",
      "          0.1572,  0.2429, -0.0031,  0.1389,  0.1611,  0.1907, -0.0405, -0.0183,\n",
      "          0.1191,  0.2176, -0.0235,  0.0594,  0.4031, -0.1192,  0.0893,  0.3296,\n",
      "          0.2979, -0.0102, -0.1475,  0.0191,  0.4348,  0.0403, -0.0377,  0.2116,\n",
      "          0.1814,  0.0923,  0.2995,  0.1824,  0.3258,  0.2539,  0.2382, -0.1941,\n",
      "          0.4336, -0.2562, -0.0545,  0.1267, -0.0032,  0.0273,  0.1300, -0.1062,\n",
      "         -0.0863, -0.2782, -0.0714, -0.4292, -0.0666, -0.3192, -0.0154,  0.2122,\n",
      "          0.0697,  0.3300,  0.4160,  0.3975, -0.0073,  0.1405, -0.0590,  0.1727,\n",
      "          0.4150,  0.4187,  0.0482,  0.2213,  0.0806,  0.4085,  0.0273,  0.3499,\n",
      "          0.3199, -0.0328,  0.0095]])\n",
      "tensor([[ 0.1033, -0.1204,  0.2297,  0.2403, -0.1892, -0.3606, -0.1231,  0.4675,\n",
      "          0.2679,  0.4817,  0.3106,  0.2650,  0.2313,  0.1732,  0.3986,  0.3281,\n",
      "         -0.0025,  0.0354,  0.1714,  0.0049,  0.2674,  0.2006, -0.0098,  0.1245,\n",
      "          0.1664,  0.2867, -0.1516,  0.1998,  0.0294,  0.0790, -0.1411,  0.0461,\n",
      "          0.1578,  0.2467,  0.0413,  0.0251,  0.4060,  0.1037, -0.0553, -0.1605,\n",
      "         -0.0218,  0.0927, -0.2978, -0.0680,  0.1922, -0.1856, -0.3319, -0.1321,\n",
      "          0.2773, -0.2092,  0.1014,  0.3168, -0.1823, -0.0543, -0.0285,  0.2952,\n",
      "         -0.0881, -0.2901,  0.0904, -0.3164,  0.4421,  0.3183,  0.0506, -0.3466,\n",
      "          0.3983,  0.3597,  0.5486, -0.3157, -0.1296, -0.0270,  0.1726,  0.2956,\n",
      "         -0.0816,  0.1171,  0.2223,  0.2111,  0.0953,  0.6066, -0.0314, -0.0365,\n",
      "          0.1292, -0.2273, -0.1879,  0.0995,  0.1490, -0.0578,  0.1909, -0.1398,\n",
      "         -0.2017,  0.1087,  0.2433,  0.2743,  0.0931,  0.1197,  0.0797,  0.0157,\n",
      "          0.2238,  0.0887, -0.1672, -0.0743, -0.2088,  0.1624,  0.0756,  0.0908,\n",
      "          0.1387, -0.0375, -0.1312, -0.1891, -0.1566,  0.0371,  0.0631,  0.1968,\n",
      "         -0.1939,  0.0389,  0.0630,  0.2132,  0.1710,  0.4991,  0.3161,  0.0520,\n",
      "          0.2476,  0.3334,  0.0833,  0.2189,  0.0904,  0.2462,  0.2145,  0.0399,\n",
      "          0.2475,  0.4078, -0.0554, -0.4347, -0.0187,  0.1539,  0.1473,  0.2018,\n",
      "          0.2001,  0.0096,  0.1670]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    start_scores = outputs.start_logits\n",
    "    end_scores = outputs.end_logits\n",
    "\n",
    "# want to see some logits?!!\n",
    "print(outputs.start_logits)\n",
    "print(outputs.end_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d875944-74f2-4b7d-b249-6ae7fb1af009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_start=69, answer_end=78\n",
      "answer=peyster sighted nukufetau\n"
     ]
    }
   ],
   "source": [
    "answer_start = torch.argmax(start_scores)\n",
    "answer_end = torch.argmax(end_scores) + 1\n",
    "\n",
    "# Convert tokens to string\n",
    "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "print(f\"answer_start={answer_start}, answer_end={answer_end}\")\n",
    "print(f\"answer={answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bc45fd-07d4-4f3e-99e9-c084396c90a5",
   "metadata": {},
   "source": [
    "Well, it tried.  We are using BERT mini after all....\n",
    "\n",
    "There are (at least) two problems with the above code.  The first is that we have not constrained the answer to start inside the context tokens.  The second is that we have not constrained the answer to end after the start.  Let's write a function that takes a question and context and returns an answer that fixes these two problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f40d2-044d-4363-bb5c-5dae2fd46db4",
   "metadata": {},
   "source": [
    "# TODO (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f74a57e1-b3c6-4678-a942-559d56e30196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Please implement the following method\n",
    "\n",
    "def answer_question(question, context, model):\n",
    "    \"\"\"\n",
    "    This method should return an answer predicted by the model.\n",
    "    Use the code above and add a bit of logic to make sure that the answer is found in the context.  \n",
    "    Also, make sure this method finds the best answer end that follows the best answer start.  \n",
    "    That is you should argmax over only the end scores that appear after the answer start\n",
    "    It's very easy to get index arithmetic wrong - so please test every line of code.\n",
    "    \"\"\"\n",
    "    # I added a couple of parameters to deal with a few examples whose questions + contexts were too long\n",
    "    inputs = tokenizer(question, context, return_tensors='pt', truncation=True, max_length=512)\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "    with torch.no_grad():\n",
    "        outputs_logits = model(**inputs)\n",
    "        start_scores = outputs_logits.start_logits\n",
    "        end_scores = outputs_logits.end_logits\n",
    "        \n",
    "    num_tokens = len(input_ids)\n",
    "    answer_start = torch.argmax(start_scores[0][:num_tokens])\n",
    "    #Our answer shouldn't be longer than 43 tokens\n",
    "    window_end = answer_start + 43\n",
    "    end_scores = end_scores[0][answer_start:window_end]\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "    answer_end += answer_start\n",
    "\n",
    "    # print(\"answer start\", answer_start)\n",
    "    # print(\"answer end\", answer_end)\n",
    "\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67a31637-2906-4e24-9657-5b5d486bb668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example: question = 'When did the Soviet Union break up?', context = 'On December 25, 1991, following the collapse of the Soviet Union, the republic was renamed the Russian Federation, which it remains to this day. This name and \"Russia\" were specified as the official state names in the April 21, 1992 amendment to the existing constitution and were retained as such in the 1993 Constitution of Russia.'\n",
      "expected answer = December 25, 1991\n",
      "actual answer = ? [SEP] on december 25 , 1991 , following the collapse of the soviet union , the republic was renamed the russian\n"
     ]
    }
   ],
   "source": [
    "# test a random example\n",
    "index = random.randint(0, train_count - 1)\n",
    "example = squad['train'][index]\n",
    "question = example['question']\n",
    "context = example['context']\n",
    "print(f\"example: question = '{question}', context = '{context}'\")\n",
    "print(f\"expected answer = {example['answers']['text'][0]}\")\n",
    "actual_answer = answer_question(question, context, model)\n",
    "print(f\"actual answer = {actual_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dba107-9a11-4587-9f8b-eb783c086ca9",
   "metadata": {},
   "source": [
    "# How many of the training examples does BERT mini get correct?\n",
    "The final bit of code to write is a loop that calls answer_question for each example in the training data and reports the number of times BERT mini gets the answer correct. Put your answer on the next line:\n",
    "\n",
    "# The number of questions BERT mini answers correctly is 16-20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a87b67-9780-436c-8cee-bb2b48300190",
   "metadata": {},
   "source": [
    "# TODO (10 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ac821f87-360e-42ee-982e-7d671603bf00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples to run: 87599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 5000, correct = 1\n",
      "progress = 10000, correct = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 15000, correct = 4\n",
      "progress = 20000, correct = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 25000, correct = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 30000, correct = 6\n",
      "progress = 35000, correct = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 40000, correct = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 45000, correct = 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 50000, correct = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 55000, correct = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 60000, correct = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 65000, correct = 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 70000, correct = 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 75000, correct = 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 80000, correct = 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress = 85000, correct = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=16\n"
     ]
    }
   ],
   "source": [
    "# TODO write some code that loops over each example in the training data and calls the answer_question() method for each\n",
    "# if the expected answer is the same as the actual, model-generated answer, then count it as correct\n",
    "# Count all the correct answers and indicate it in the markdown block above\n",
    "# This code may take a while (30 minutes or more) and so you might consider adding progress updates\n",
    "# here's the code I used\n",
    "# progress = 0\n",
    "# (inside the loop)\n",
    "# progress += 1\n",
    "# if progress % 5000 == 0:\n",
    "#     print(f\"progress = {progress}, correct = {correct}\")\n",
    "\n",
    "correct = 0\n",
    "progress = 0\n",
    "print(\"Total examples to run:\", len(squad['train']))\n",
    "\n",
    "for example in squad['train']:\n",
    "    progress += 1\n",
    "    if progress % 5000 == 0:\n",
    "        print(f\"progress = {progress}, correct = {correct}\")\n",
    " \n",
    "    question = example['question']\n",
    "    context = example['context']\n",
    "    expected_answer = example['answers']['text'][0].lower().strip()\n",
    "    predicted_answer = answer_question(question, context, model).lower().strip()\n",
    "    if expected_answer == predicted_answer:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"correct={correct}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
